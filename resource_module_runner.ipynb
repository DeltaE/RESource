{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "``/local-scratch/localhome/mei3/eliasinul/work/BC_Combined_Modelling/models/RESource/data/store/resources_BC.h5`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m store\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/store/resources_BC.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m res_data\u001b[38;5;241m=\u001b[39mDataHandler(store)\n\u001b[0;32m----> 4\u001b[0m cells\u001b[38;5;241m=\u001b[39m\u001b[43mres_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcells\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m boundary\u001b[38;5;241m=\u001b[39mres_data\u001b[38;5;241m.\u001b[39mfrom_store(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m solar_clusters\u001b[38;5;241m=\u001b[39mres_data\u001b[38;5;241m.\u001b[39mfrom_store(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters/solar\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/local-scratch/localhome/mei3/eliasinul/work/BC_Combined_Modelling/models/RESource/RES/hdf5_handler.py:98\u001b[0m, in \u001b[0;36mDataHandler.from_store\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_store\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     90\u001b[0m                key: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    Load data from the HDF5 store and handle geometry conversion.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    :param key: Key for loading the DataFrame or GeoDataFrame.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    :return: DataFrame or GeoDataFrame based on the data loaded.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHDFStore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m store:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m store:\n\u001b[1;32m    100\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Key \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/pandas/io/pytables.py:585\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fletcher32 \u001b[38;5;241m=\u001b[39m fletcher32\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/pandas/io/pytables.py:745\u001b[0m, in \u001b[0;36mHDFStore.open\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    740\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meven in read-only mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    742\u001b[0m     )\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43mtables\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/tables/file.py:296\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already opened.  Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose it before reopening in write mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_uep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/tables/file.py:746\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    745\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 746\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    749\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/tables/hdf5extension.pyx:396\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc_combined_modelling/lib/python3.12/site-packages/tables/utils.py:166\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# The file should be readable.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(path, os\u001b[38;5;241m.\u001b[39mF_OK):\n\u001b[0;32m--> 166\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` is not a regular file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: ``/local-scratch/localhome/mei3/eliasinul/work/BC_Combined_Modelling/models/RESource/data/store/resources_BC.h5`` does not exist"
     ]
    }
   ],
   "source": [
    "from RES.hdf5_handler import DataHandler\n",
    "store=\"data/store/resources_BC.h5\"\n",
    "res_data=DataHandler(store)\n",
    "cells=res_data.from_store('cells')\n",
    "boundary=res_data.from_store('boundary')\n",
    "solar_clusters=res_data.from_store('clusters/solar')\n",
    "wind_clusters=res_data.from_store('clusters/wind')\n",
    "wind_ts=res_data.from_store('timeseries/wind')\n",
    "solar_ts=res_data.from_store('timeseries/solar')\n",
    "solar_clusters_ts=res_data.from_store('timeseries/clusters/solar')\n",
    "wind_clusters_ts=res_data.from_store('timeseries/clusters/wind')\n",
    "di_wind=res_data.from_store('dissolved_indices/wind')\n",
    "di_solar=res_data.from_store('dissolved_indices/solar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RES.RESources as REsources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Main module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RES.utility:Directory 'data/downloaded_data/NREL/ATB/ATBe.parquet' found locally.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m____________________________________________________________\u001b[0m\n",
      "\u001b[92m     Initiating RESource Builder...\u001b[0m\n",
      "\u001b[96m____________________________________________________________\u001b[0m\n",
      "\u001b[36m └> NREL_ATBProcessor initiated...\u001b[0m\n",
      "\u001b[95m  └> Processing Annual Technology Baseline (ATB) data sourced from NREL...\u001b[0m\n",
      "\u001b[95m  └> ATB cost datafile: ATBe.parquet loaded\u001b[0m\n",
      "\u001b[95m  └> Extracting technology baseline costs...\u001b[0m\n",
      "\u001b[90m\u001b[2m  └─> Extracting Solar PV technology cost...\u001b[0m\n",
      ">> Data (GeoDataFrame/DataFrame) saved to data/store/resources_BC.h5 with key 'cost/atb/solar'\n",
      "\u001b[90m\u001b[2m  └─> Extracting Wind Turbine technology cost...\u001b[0m\n",
      ">> Data (GeoDataFrame/DataFrame) saved to data/store/resources_BC.h5 with key 'cost/atb/wind'\n",
      "\u001b[90m\u001b[2m  └─> Extracting BESS technology cost...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RES.AttributesParser:>> Loading GADM boundaries (Sub-provincial | level =2) for British Columbia  from local file data/processed_data/regions/gadm41_Canada_L2_BC.geojson.\n",
      "INFO:atlite.data:Storing temporary files in /tmp/tmpy8h0yexg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Data (GeoDataFrame/DataFrame) saved to data/store/resources_BC.h5 with key 'cost/atb/bess'\n",
      "\u001b[36m └> Snapshot for Resources: 2023-01-01 07:00:00 to 2024-01-01 06:00:00\u001b[0m\n",
      "__________________________________________________\n",
      " Initiating solar module for British Columbia...\n",
      "\u001b[36m └> Preparing Grid Cells...\u001b[0m\n",
      "\n",
      "    >>> Memory management remarks:\n",
      "    * After execution, all downloaded data is stored at cutout.path. By default, it is not loaded into memory, but into dask arrays. This keeps the memory consumption extremely low.\n",
      "    * The data is accessible in cutout.data, which is an xarray.Dataset. Querying the cutout gives us some basic information on which data is contained in it.\n",
      "    * For more operations related to cutout, check the tool docs @ https://atlite.readthedocs.io/en/master/examples/create_cutout.html#\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RES.AttributesParser:>> Loading GADM boundaries (Sub-provincial | level =2) for British Columbia  from local file data/processed_data/regions/gadm41_Canada_L2_BC.geojson.\n",
      "INFO:atlite.data:Storing temporary files in /tmp/tmpmt8g08ew\n",
      "INFO:RES.AttributesParser:>> Loading global filters' rasters from GAEZ, trimmed to British Columbia\n",
      "INFO:RES.AttributesParser:>> Raster file 'faocmb_2010.tif' already exists locally.\n",
      "INFO:RES.AttributesParser:>> Raster file 'slpmed05.tif' already exists locally.\n",
      "INFO:RES.AttributesParser:>> Raster file 'exclusion_2017.tif' already exists locally.\n",
      "INFO:RES.AttributesParser:>> Loading GADM boundaries (Sub-provincial | level =2) for British Columbia  from local file data/processed_data/regions/gadm41_Canada_L2_BC.geojson.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Updated 'cells' saved to data/store/resources_BC.h5 with key 'cells'\n",
      ">> Updated 'boundary' saved to data/store/resources_BC.h5 with key 'boundary'\n",
      "\u001b[95m  └> Grid Cells updated.\u001b[0m\n",
      "\u001b[36m └> Preparing Cells' capacity ...\u001b[0m\n",
      "\n",
      "    >>> Memory management remarks:\n",
      "    * After execution, all downloaded data is stored at cutout.path. By default, it is not loaded into memory, but into dask arrays. This keeps the memory consumption extremely low.\n",
      "    * The data is accessible in cutout.data, which is an xarray.Dataset. Querying the cutout gives us some basic information on which data is contained in it.\n",
      "    * For more operations related to cutout, check the tool docs @ https://atlite.readthedocs.io/en/master/examples/create_cutout.html#\n",
      "        \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RES.AttributesParser:>> Raster plot saved at: vis/misc/faocmb_2010_raster_BC.png\n",
      "INFO:RES.AttributesParser:>> Raster plot saved at: vis/misc/slpmed05_raster_BC.png\n",
      "INFO:RES.AttributesParser:>> Raster plot saved at: vis/misc/exclusion_2017_raster_BC.png\n",
      "INFO:RES.AttributesParser:All required rasters for GAEZ processed and plotted successfully.\n",
      "INFO:RES.AttributesParser: >>> Loading Land_cover layers from data/downloaded_data/GAEZ/Rasters_in_use/LR/lco/BC_faocmb_2010.tif\n",
      "INFO:RES.AttributesParser: >>> Loading Terrain_resources layers from data/downloaded_data/GAEZ/Rasters_in_use/LR/ter/BC_slpmed05.tif\n",
      "INFO:RES.AttributesParser: >>> Loading Exclusion_areas layers from data/downloaded_data/GAEZ/Rasters_in_use/LR/excl/BC_exclusion_2017.tif\n",
      "INFO:RES.AttributesParser:> Loading Canadian Protected and Conserved Areas Database (CPCAD) from locally stored datafile - data/downloaded_data/lands/ProtectedConservedArea_BC.pickle\n",
      "INFO:RES.AttributesParser:>> Loading locally stored OSM data for 'aeroway' from data/downloaded_data/OSM/BC_aeroway.geojson\n",
      "INFO:RES.AttributesParser:Exclusion Container\n",
      " registered rasters: 3 \n",
      " registered geometry collections: 2\n",
      " CRS: 3347 - Resolution: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land availability (grid cells) map saved at vis/misc/land_availability_ERA5grid_British Columbia.png\n",
      "Land availability map (excluder resolution) saved at vis/misc/land_availability_excluderResolution_British Columbia.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:RES.AttributesParser:>> Saving to the local store (as HDF5 file)\n",
      "INFO:RES.AttributesParser:>> Loading GADM boundaries (Sub-provincial | level =2) for British Columbia  from local file data/processed_data/regions/gadm41_Canada_L2_BC.geojson.\n",
      "INFO:atlite.data:Storing temporary files in /tmp/tmp73y3s1k1\n",
      "INFO:RES.AttributesParser:>> Loading ERA5 Cutout\n",
      "INFO:RES.AttributesParser:>> Loading GADM boundaries (Sub-provincial | level =2) for British Columbia  from local file data/processed_data/regions/gadm41_Canada_L2_BC.geojson.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Total ERA5 cells loaded : 2958 [each with .025 deg. (~30km) resolution ]\n",
      ">> Updated 'cells' saved to data/store/resources_BC.h5 with key 'cells'\n",
      "\u001b[95m  └> Cells' capacity updated..\u001b[0m\n",
      "\u001b[36m └> Extracting ERA5 weather data...\u001b[0m\n",
      "\n",
      "    >>> Memory management remarks:\n",
      "    * After execution, all downloaded data is stored at cutout.path. By default, it is not loaded into memory, but into dask arrays. This keeps the memory consumption extremely low.\n",
      "    * The data is accessible in cutout.data, which is an xarray.Dataset. Querying the cutout gives us some basic information on which data is contained in it.\n",
      "    * For more operations related to cutout, check the tool docs @ https://atlite.readthedocs.io/en/master/examples/create_cutout.html#\n",
      "        \n",
      "\u001b[95m  └> GWA Cells not configured for solar.\u001b[0m\n",
      "\u001b[90m\u001b[2m  └─> Preparing Timeseries for the Cells...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:atlite.data:Storing temporary files in /tmp/tmptv7a37e_\n",
      "INFO:RES.AttributesParser:>> 2948 Grid Cells from Store Cutout\n",
      "INFO:atlite.convert:Convert and aggregate 'pv'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    >>> Memory management remarks:\n",
      "    * After execution, all downloaded data is stored at cutout.path. By default, it is not loaded into memory, but into dask arrays. This keeps the memory consumption extremely low.\n",
      "    * The data is accessible in cutout.data, which is an xarray.Dataset. Querying the cutout gives us some basic information on which data is contained in it.\n",
      "    * For more operations related to cutout, check the tool docs @ https://atlite.readthedocs.io/en/master/examples/create_cutout.html#\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "REsources.build_resources(provinces=['BC'],  #'BC','AB','SK','ON','NS','MB'\n",
    "                          resource_types=['solar','wind'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- Test Starts--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over provinces for both solar and wind resources\n",
    "# resource_types = ['wind'] # , ,'solar'\n",
    "# provinces=['BC']  #'AB','SK','ON','NS'\n",
    "# for province_code in provinces:\n",
    "#     for resource_type in resource_types:\n",
    "#         required_args = {\n",
    "#             \"config_file_path\": 'config/config.yaml',\n",
    "#             \"province_short_code\": province_code,\n",
    "#             \"resource_type\": resource_type\n",
    "#         }\n",
    "        \n",
    "#         # Create an instance of Resources and execute the module\n",
    "#         RES_module = REsources.RESources_builder(**required_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1=RES_module.get_grid_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2=RES_module.get_cell_capacity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3=RES_module.extract_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data4=RES_module.update_gwa_scaled_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data5=RES_module.get_CF_timeseries(cells)\n",
    "# data6=RES_module.find_grid_nodes(cells,\n",
    "#                                  use_pypsa_buses=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data7=RES_module.score_cells()\n",
    "# data8=RES_module.get_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data9=RES_module.get_cluster_timeseries(solar_clusters,\n",
    "#                                         di_solar,\n",
    "#                                         solar_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resource_clusters_wind,cluster_timeseries_wind=RES_module.select_top_sites(wind_clusters,\n",
    "#                                                                 wind_clusters_ts,\n",
    "#                                                                     resource_max_capacity=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resource_clusters_solar,cluster_timeseries_solar=RES_module.select_top_sites(solar_clusters,\n",
    "#                                                                 solar_clusters_ts,\n",
    "#                                                                     resource_max_capacity=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- Test Ends --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_CRF(#self,\n",
    "            r, \n",
    "            N):\n",
    "    return (r * (1 + r) ** N) / ((1 + r) ** N - 1) if N > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calculate_total_cost(#self, \n",
    "                             distance_to_grid_km: float, \n",
    "                             grid_connection_cost_per_km: float, \n",
    "                             tx_line_rebuild_cost: float, \n",
    "                             capex_tech: float,\n",
    "                             capacity_MW:float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate the total cost, which includes the CAPEX and distance-based grid connection costs.\n",
    "        Method: Simple Levelized Cost of Energy Calculation (https://www.nrel.gov/analysis/tech-lcoe-documentation.html)\n",
    "        \"\"\"\n",
    "        # Calculate distance-based cost\n",
    "        add_to_grid_cost = (distance_to_grid_km * grid_connection_cost_per_km / 1.60934) * (tx_line_rebuild_cost / 1.60934)  # Convert to miles as our costs are given in $/miles (USA study)\n",
    "\n",
    "        # Total cost is CAPEX plus distance cost\n",
    "        total_cost = capex_tech*capacity_MW + add_to_grid_cost  # in M$\n",
    "        \n",
    "        return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resource_type='wind'\n",
    "interest_rate=0.03\n",
    "N=cells[f'Operational_life_{resource_type}'].iloc[0]\n",
    "CRF=get_CRF(interest_rate,N)\n",
    "CF_column='wind_CF_mean'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def calculate_lcoe(row) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the potential LCOE score for each cell in the dataframe,\n",
    "    reading cost parameters directly from the DataFrame.\n",
    "    \n",
    "    ## Args:\n",
    "    - **row** : A single row of the DataFrame.m\n",
    "    \n",
    "    ## Returns:\n",
    "    - **float** : The calculated LCOE value for the row.\n",
    "    \"\"\"\n",
    "    # Calculate the total cost\n",
    "    total_cost = calculate_total_cost(\n",
    "        row['nearest_station_distance_km'],  # km\n",
    "        row[f'grid_connection_cost_per_km_{resource_type}'],  # m$/km\n",
    "        row[f'tx_line_rebuild_cost_{resource_type}'],  # m$/km\n",
    "        row[f'capex_{resource_type}'],\n",
    "        row[f'potential_capacity_{resource_type}']# MW\n",
    "    ) # mW\n",
    "    \n",
    "    annual_energy = 8760  * row[CF_column] * row[f'potential_capacity_{resource_type}']# Total energy produced in a year\n",
    "    if annual_energy == 0: # some cells have no potentials\n",
    "        return float(99999)  # handle the error \n",
    "    else:\n",
    "        # Calculate the LCOE\n",
    "\n",
    "        lcoe = (total_cost * CRF / annual_energy)  # Avoid division by zero,  m$/MWh\n",
    "    \n",
    "        return lcoe *1E6 # Convert to $/MWh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cells_test=cells.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cells_test[f'LCOE_{resource_type}'] = cells_test.apply(lambda row: calculate_lcoe(row), axis=1) # LCOE in $/MWh  # adopting NREL's method + some added costs\n",
    "scored_dataframe = cells_test.sort_values(by=f'LCOE_{resource_type}', ascending=True).copy()  # Lower LCOE is better\n",
    "scored_dataframe.head(10).LCOE_wind"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc_combined_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
